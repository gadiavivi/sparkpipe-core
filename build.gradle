/**
 * $ ./gradlew
 * The default task will build the project and run the test suite inside
 * your local spark environment (spark-submit must be on the PATH).
 *
 * To build and install library, run ./gradlew jar install
 *
 * To generate documentation and docs JAR, run ./gradlew docsJar
 *
 * A coverage report will be present at build/reports/scoverage/index.html
 *
 * TODO integrate https://github.com/kt3k/coveralls-gradle-plugin
 */

 group = 'software.uncharted.sparkpipe'
 version = '1.1.0-SNAPSHOT'

 project.ext {
   scalaBinaryVersion = '2.11'
   scalaVersion = '2.11.8'
   sparkVersion = System.getenv("SPARK_VERSION") ?: '2.0.1'
   scoverageVersion = '1.1.1'
   scalatestVersion = '2.2.6'
   pegdownVersion = '1.6.0'
   mockitoVersion = '1.10.19'
   packages = "org.mockito:mockito-all:${mockitoVersion},org.scalatest:scalatest_${scalaBinaryVersion}:${scalatestVersion},org.scoverage:scalac-scoverage-runtime_${scalaBinaryVersion}:${scoverageVersion}"
   artifactName = 'sparkpipe-core'
   description = 'A Spark Scala library for creating modular, non-linear data pipelines.'
   inceptionYear = '2015'
   url = 'https://github.com/unchartedsoftware/sparkpipe'
   ossrhUsername = project.hasProperty('ossrhUsername') ? project.getProperty('ossrhUsername') : ''
   ossrhPassword = project.hasProperty('ossrhPassword') ? project.getProperty('ossrhPassword') : ''
 }

buildscript {
  repositories {
    mavenLocal()
    mavenCentral()
    jcenter()
  }
  dependencies {
    classpath "com.github.maiflai:gradle-scalatest:0.12"
    classpath "org.github.ngbinh.scalastyle:gradle-scalastyle-plugin_2.10:0.8.2"
    classpath "org.kt3k.gradle.plugin:coveralls-gradle-plugin:2.6.3"
    classpath "org.scoverage:gradle-scoverage:2.0.1"
  }
}

apply plugin: 'com.github.kt3k.coveralls'
apply plugin: 'com.github.maiflai.scalatest'
apply plugin: 'idea'
apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'org.scoverage'
apply plugin: 'scala'
apply plugin: 'scalaStyle'
apply plugin: 'signing'

sourceCompatibility = 1.7
targetCompatibility = 1.7

repositories {
  mavenLocal()
  mavenCentral()
}

configurations {
  provided
}

jar {
  baseName = "${artifactName}"
  version =  version
  dependsOn configurations.runtime
  from {
    (configurations.runtime - configurations.provided).collect {
      it.isDirectory() ? it : zipTree(it)
    }
  } {
    exclude "META-INF/*.SF"
    exclude "META-INF/*.DSA"
    exclude "META-INF/*.RSA"
  }
}

task docs(type: ScalaDoc) {
  source = sourceSets.main.allScala
}

task docsJar(type: Jar, dependsOn: docs) {
  classifier = 'javadoc'
  from docs.destinationDir
}

task sourcesJar(type: Jar) {
  classifier = 'sources'
  from sourceSets.main.allSource
}

checkScoverage {
  minimumRate = 1
}

task testJar(type: Jar) {
  classifier = 'tests'
  from sourceSets.test.output
}

task startTestEnv(overwrite: true, type: Exec) {
  executable = './test-environment.sh'
  args = ["start"]
}

task stopTestEnv(overwrite: true, type: Exec) {
  executable = './test-environment.sh'
  args = ["stop"]
}

task test(overwrite: true, type: Exec, dependsOn: [startTestEnv, jar, jarScoverage, testJar, docsJar, scalaStyle]) {
  executable = 'docker'
  args = ["exec", project.name, "spark-submit", "--packages", packages,"--jars","build/libs/${artifactName}-${version}-scoverage.jar","--class","software.uncharted.sparkpipe.Main","build/libs/${artifactName}-${version}-tests.jar"]
}
// test.finalizedBy stopTestEnv // this does slow down development, so we'll make it manual instead of automatic

task debug(overwrite: true, type: Exec, dependsOn: [startTestEnv, jar, jarScoverage, testJar, docsJar, scalaStyle]) {
  executable = 'docker'
  args = ["exec", project.name, "/bin/bash", "-c", "export SPARK_JAVA_OPTS=\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=9999\" && spark-submit --packages ${packages} --jars build/libs/${artifactName}-${version}-scoverage.jar --class software.uncharted.sparkpipe.Main build/libs/${artifactName}-${version}-tests.jar"]
}
// debug.finalizedBy stopTestEnv // this does slow down development, so we'll make it manual instead of automatic

task coverage(overwrite: true, dependsOn: test) << {
  reportScoverage.execute()
  checkScoverage.execute()
}

coveralls {
  coberturaReportPath = "${buildDir}/reports/scoverage/cobertura.xml"
}

//////////////////////////////////////
//BEGIN nexus oss
//////////////////////////////////////
artifacts {
  archives docsJar, testJar, sourcesJar
}
signing {
  sign configurations.archives
}
//make sure assemble doesn't depend on signing
gradle.taskGraph.whenReady { taskGraph ->
  def tasks = taskGraph.getAllTasks()
  if (tasks.find {it.name == 'assemble'}) {
    tasks.findAll {it.name == 'signArchives' || it.name == 'signDocsJar' || it.name == 'signTestJar' || it.name == 'signSourcesJar'}.each { task ->
      task.enabled = false
    }
  }
}
uploadArchives {
  repositories {
    mavenDeployer {
      beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

      repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      pom.project {
        name = artifactName
        packaging = 'jar'
        // optionally artifactId can be defined here
        description = description
        url = url

        scm {
          connection 'scm:git:git://github.com/unchartedsoftware/sparkpipe.git'
          developerConnection 'scm:git:git@github.com:unchartedsoftware/sparkpipe.git'
          url 'https://github.com/unchartedsoftware/sparkpipe'
        }

        licenses {
          license {
            name 'The Apache License, Version 2.0'
            url 'http://www.apache.org/licenses/LICENSE-2.0.txt'
          }
        }

        developers {
          developer {
            id = 'smcintyre'
            name = 'Sean McIntyre'
            email = 'smcintyre@uncharted.software'
          }
        }
      }
    }
  }
}
//////////////////////////////////////
//END nexus oss
//////////////////////////////////////

scalaStyle {
  configLocation = "scalastyle_config.xml"
  includeTestSourceDirectory = true
  source = sourceSets.main.allScala
  testSource = sourceSets.test.allScala
  failOnWarning = true
}

sourceSets {
  main { compileClasspath += configurations.provided }
  test {
    compileClasspath += configurations.provided
    runtimeClasspath += configurations.provided
  }
  scoverage { compileClasspath += configurations.provided }
  testScoverage { compileClasspath += configurations.provided }
}

dependencies {
    //scala
    provided("org.scala-lang:scala-library:${scalaVersion}")

    //spark
    provided "org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}"
    //provided "org.apache.spark:spark-streaming_${scalaBinaryVersion}:${sparkVersion}"
    //provided "org.apache.spark:spark-graphx_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.apache.spark:spark-mllib_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.scala-lang:scala-library:${scalaBinaryVersion}"

    //scalatest
    testCompile "org.scalatest:scalatest_${scalaBinaryVersion}:${scalatestVersion}"
    testRuntime "org.pegdown:pegdown:${pegdownVersion}"

    //mockito
    testCompile "org.mockito:mockito-all:${mockitoVersion}"

    //scoverage
    scoverage "org.scoverage:scalac-scoverage-plugin_${scalaBinaryVersion}:${scoverageVersion}",
            "org.scoverage:scalac-scoverage-runtime_${scalaBinaryVersion}:${scoverageVersion}"
}

task wrapper(type: Wrapper) {
    gradleVersion = '2.13'
}

idea {
    module {
        inheritOutputDirs = false
        outputDir = file("$buildDir/classes/main/")
        scopes.PROVIDED.plus += [ configurations.provided ]
    }
}

defaultTasks 'coverage'
